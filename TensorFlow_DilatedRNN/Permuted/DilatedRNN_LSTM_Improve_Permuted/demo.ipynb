{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Permuted Pixel MNIST Demo \n",
    "Light weighted demo of our DilatedRNN on Pixel MNist with permutation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./models\")\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from classification_models import drnn_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurations\n",
    "data_dir = \"./MNIST_data\"\n",
    "n_steps = 28*28\n",
    "input_dims = 1\n",
    "n_classes = 10 \n",
    "\n",
    "# model config\n",
    "cell_type = \"LSTM\"\n",
    "assert(cell_type in [\"RNN\", \"LSTM\", \"GRU\"])\n",
    "hidden_structs = [20] * 9\n",
    "dilations = [1, 2, 4, 8, 16, 32, 64, 128, 256]\n",
    "assert(len(hidden_structs) == len(dilations))\n",
    "\n",
    "# learning config\n",
    "batch_size = 128\n",
    "learning_rate = 1.0e-3\n",
    "training_iters = batch_size * 60000\n",
    "testing_step = 5000\n",
    "display_step = 100\n",
    "\n",
    "# permutation seed \n",
    "seed = 92916"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(data_dir, one_hot=True)\n",
    "if 'seed' in globals():\n",
    "    # randomly permute np.arange(n_steps), seed is the state, if the state is the same, the result is the same \n",
    "    rng_permute = np.random.RandomState(seed)\n",
    "    idx_permute = rng_permute.permutation(n_steps)\n",
    "else:\n",
    "    idx_permute = np.random.permutation(n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Building a dRNN with LSTM cells\n",
      "Building layer: multi_dRNN_dilation_1, input length: 784, dilation rate: 1, input dim: 1.\n",
      "=====> Input length for sub-RNN: 784\n",
      "Building layer: multi_dRNN_dilation_2, input length: 784, dilation rate: 2, input dim: 20.\n",
      "=====> Input length for sub-RNN: 392\n",
      "Building layer: multi_dRNN_dilation_4, input length: 784, dilation rate: 4, input dim: 20.\n",
      "=====> Input length for sub-RNN: 196\n",
      "Building layer: multi_dRNN_dilation_8, input length: 784, dilation rate: 8, input dim: 20.\n",
      "=====> Input length for sub-RNN: 98\n",
      "Building layer: multi_dRNN_dilation_16, input length: 784, dilation rate: 16, input dim: 20.\n",
      "=====> Input length for sub-RNN: 49\n",
      "Building layer: multi_dRNN_dilation_32, input length: 784, dilation rate: 32, input dim: 20.\n",
      "=====> 16 time points need to be padded. \n",
      "=====> Input length for sub-RNN: 25\n",
      "Building layer: multi_dRNN_dilation_64, input length: 784, dilation rate: 64, input dim: 20.\n",
      "=====> 48 time points need to be padded. \n",
      "=====> Input length for sub-RNN: 13\n",
      "Building layer: multi_dRNN_dilation_128, input length: 784, dilation rate: 128, input dim: 20.\n",
      "=====> 112 time points need to be padded. \n",
      "=====> Input length for sub-RNN: 7\n",
      "Building layer: multi_dRNN_dilation_256, input length: 784, dilation rate: 256, input dim: 20.\n",
      "=====> 240 time points need to be padded. \n",
      "=====> Input length for sub-RNN: 4\n"
     ]
    }
   ],
   "source": [
    "# build computation graph\n",
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, [None, n_steps, input_dims])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])    \n",
    "global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "\n",
    "# build prediction graph\n",
    "print (\"==> Building a dRNN with %s cells\" %cell_type)\n",
    "pred = drnn_classification(x, hidden_structs, dilations, n_steps, n_classes, input_dims, cell_type)\n",
    "\n",
    "# build loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost, global_step=global_step)\n",
    "\n",
    "# evaluation model\n",
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 100, Minibatch Loss: 2.246158, Training Accuracy: 0.164062\n",
      "Iter 200, Minibatch Loss: 2.189928, Training Accuracy: 0.164062\n",
      "Iter 300, Minibatch Loss: 2.102141, Training Accuracy: 0.171875\n",
      "Iter 400, Minibatch Loss: 2.057165, Training Accuracy: 0.296875\n",
      "Iter 500, Minibatch Loss: 1.929759, Training Accuracy: 0.296875\n",
      "Iter 600, Minibatch Loss: 1.861923, Training Accuracy: 0.320312\n",
      "Iter 700, Minibatch Loss: 1.955286, Training Accuracy: 0.343750\n",
      "Iter 800, Minibatch Loss: 1.879047, Training Accuracy: 0.281250\n",
      "Iter 900, Minibatch Loss: 1.791505, Training Accuracy: 0.367188\n",
      "Iter 1000, Minibatch Loss: 1.664365, Training Accuracy: 0.359375\n",
      "Iter 1100, Minibatch Loss: 1.801519, Training Accuracy: 0.367188\n",
      "Iter 1200, Minibatch Loss: 1.755046, Training Accuracy: 0.437500\n",
      "Iter 1300, Minibatch Loss: 1.662185, Training Accuracy: 0.414062\n",
      "Iter 1400, Minibatch Loss: 1.473197, Training Accuracy: 0.515625\n",
      "Iter 1500, Minibatch Loss: 1.505841, Training Accuracy: 0.476562\n",
      "Iter 1600, Minibatch Loss: 1.491378, Training Accuracy: 0.460938\n",
      "Iter 1700, Minibatch Loss: 1.523193, Training Accuracy: 0.468750\n",
      "Iter 1800, Minibatch Loss: 1.404463, Training Accuracy: 0.523438\n",
      "Iter 1900, Minibatch Loss: 1.425736, Training Accuracy: 0.507812\n",
      "Iter 2000, Minibatch Loss: 1.406543, Training Accuracy: 0.531250\n",
      "Iter 2100, Minibatch Loss: 1.253285, Training Accuracy: 0.570312\n",
      "Iter 2200, Minibatch Loss: 1.314419, Training Accuracy: 0.539062\n",
      "Iter 2300, Minibatch Loss: 1.299711, Training Accuracy: 0.554688\n",
      "Iter 2400, Minibatch Loss: 1.148341, Training Accuracy: 0.585938\n",
      "Iter 2500, Minibatch Loss: 1.155196, Training Accuracy: 0.593750\n",
      "Iter 2600, Minibatch Loss: 1.120505, Training Accuracy: 0.609375\n",
      "Iter 2700, Minibatch Loss: 0.954505, Training Accuracy: 0.710938\n",
      "Iter 2800, Minibatch Loss: 1.053895, Training Accuracy: 0.585938\n",
      "Iter 2900, Minibatch Loss: 1.316466, Training Accuracy: 0.523438\n",
      "Iter 3000, Minibatch Loss: 1.123979, Training Accuracy: 0.632812\n",
      "Iter 3100, Minibatch Loss: 0.957705, Training Accuracy: 0.703125\n",
      "Iter 3200, Minibatch Loss: 1.131991, Training Accuracy: 0.617188\n",
      "Iter 3300, Minibatch Loss: 0.933650, Training Accuracy: 0.695312\n",
      "Iter 3400, Minibatch Loss: 1.071728, Training Accuracy: 0.601562\n",
      "Iter 3500, Minibatch Loss: 1.138138, Training Accuracy: 0.609375\n",
      "Iter 3600, Minibatch Loss: 0.962190, Training Accuracy: 0.640625\n",
      "Iter 3700, Minibatch Loss: 0.969206, Training Accuracy: 0.656250\n",
      "Iter 3800, Minibatch Loss: 1.041727, Training Accuracy: 0.679688\n",
      "Iter 3900, Minibatch Loss: 0.761608, Training Accuracy: 0.734375\n",
      "Iter 4000, Minibatch Loss: 0.815963, Training Accuracy: 0.710938\n",
      "Iter 4100, Minibatch Loss: 0.898409, Training Accuracy: 0.718750\n",
      "Iter 4200, Minibatch Loss: 0.966267, Training Accuracy: 0.679688\n",
      "Iter 4300, Minibatch Loss: 0.886724, Training Accuracy: 0.703125\n",
      "Iter 4400, Minibatch Loss: 0.807111, Training Accuracy: 0.773438\n",
      "Iter 4500, Minibatch Loss: 0.871040, Training Accuracy: 0.695312\n",
      "Iter 4600, Minibatch Loss: 0.923113, Training Accuracy: 0.703125\n",
      "Iter 4700, Minibatch Loss: 0.778041, Training Accuracy: 0.742188\n",
      "Iter 4800, Minibatch Loss: 0.884572, Training Accuracy: 0.679688\n",
      "Iter 4900, Minibatch Loss: 0.725100, Training Accuracy: 0.765625\n",
      "Iter 5000, Minibatch Loss: 0.763792, Training Accuracy: 0.742188\n",
      "========> Validation Accuarcy: 0.742200, Testing Accuarcy: 0.742000\n",
      "Iter 5100, Minibatch Loss: 0.861221, Training Accuracy: 0.710938\n",
      "Iter 5200, Minibatch Loss: 0.659945, Training Accuracy: 0.789062\n",
      "Iter 5300, Minibatch Loss: 0.670573, Training Accuracy: 0.765625\n",
      "Iter 5400, Minibatch Loss: 0.721261, Training Accuracy: 0.796875\n",
      "Iter 5500, Minibatch Loss: 0.916314, Training Accuracy: 0.687500\n",
      "Iter 5600, Minibatch Loss: 0.697309, Training Accuracy: 0.742188\n",
      "Iter 5700, Minibatch Loss: 0.775596, Training Accuracy: 0.703125\n",
      "Iter 5800, Minibatch Loss: 0.785086, Training Accuracy: 0.750000\n",
      "Iter 5900, Minibatch Loss: 0.807128, Training Accuracy: 0.726562\n",
      "Iter 6000, Minibatch Loss: 0.746031, Training Accuracy: 0.750000\n",
      "Iter 6100, Minibatch Loss: 0.768396, Training Accuracy: 0.726562\n",
      "Iter 6200, Minibatch Loss: 0.617559, Training Accuracy: 0.781250\n",
      "Iter 6300, Minibatch Loss: 0.631229, Training Accuracy: 0.781250\n",
      "Iter 6400, Minibatch Loss: 0.655329, Training Accuracy: 0.835938\n",
      "Iter 6500, Minibatch Loss: 0.640788, Training Accuracy: 0.812500\n",
      "Iter 6600, Minibatch Loss: 0.545310, Training Accuracy: 0.835938\n",
      "Iter 6700, Minibatch Loss: 0.654849, Training Accuracy: 0.765625\n",
      "Iter 6800, Minibatch Loss: 0.665450, Training Accuracy: 0.796875\n",
      "Iter 6900, Minibatch Loss: 0.785166, Training Accuracy: 0.734375\n",
      "Iter 7000, Minibatch Loss: 0.700616, Training Accuracy: 0.773438\n",
      "Iter 7100, Minibatch Loss: 0.569916, Training Accuracy: 0.820312\n",
      "Iter 7200, Minibatch Loss: 0.679873, Training Accuracy: 0.742188\n",
      "Iter 7300, Minibatch Loss: 0.536785, Training Accuracy: 0.835938\n",
      "Iter 7400, Minibatch Loss: 0.616913, Training Accuracy: 0.812500\n",
      "Iter 7500, Minibatch Loss: 0.608748, Training Accuracy: 0.781250\n",
      "Iter 7600, Minibatch Loss: 0.541499, Training Accuracy: 0.835938\n",
      "Iter 7700, Minibatch Loss: 0.601265, Training Accuracy: 0.804688\n",
      "Iter 7800, Minibatch Loss: 0.745987, Training Accuracy: 0.773438\n",
      "Iter 7900, Minibatch Loss: 0.591972, Training Accuracy: 0.828125\n",
      "Iter 8000, Minibatch Loss: 0.589733, Training Accuracy: 0.843750\n",
      "Iter 8100, Minibatch Loss: 0.575085, Training Accuracy: 0.781250\n",
      "Iter 8200, Minibatch Loss: 0.591948, Training Accuracy: 0.804688\n",
      "Iter 8300, Minibatch Loss: 0.637830, Training Accuracy: 0.789062\n",
      "Iter 8400, Minibatch Loss: 0.620563, Training Accuracy: 0.796875\n",
      "Iter 8500, Minibatch Loss: 0.744513, Training Accuracy: 0.781250\n",
      "Iter 8600, Minibatch Loss: 0.383866, Training Accuracy: 0.898438\n",
      "Iter 8700, Minibatch Loss: 0.514671, Training Accuracy: 0.828125\n",
      "Iter 8800, Minibatch Loss: 0.547862, Training Accuracy: 0.812500\n",
      "Iter 8900, Minibatch Loss: 0.559160, Training Accuracy: 0.843750\n",
      "Iter 9000, Minibatch Loss: 0.670107, Training Accuracy: 0.773438\n",
      "Iter 9100, Minibatch Loss: 0.550716, Training Accuracy: 0.843750\n",
      "Iter 9200, Minibatch Loss: 0.502119, Training Accuracy: 0.843750\n",
      "Iter 9300, Minibatch Loss: 0.402203, Training Accuracy: 0.898438\n",
      "Iter 9400, Minibatch Loss: 0.717421, Training Accuracy: 0.757812\n",
      "Iter 9500, Minibatch Loss: 0.538571, Training Accuracy: 0.820312\n",
      "Iter 9600, Minibatch Loss: 0.648286, Training Accuracy: 0.781250\n",
      "Iter 9700, Minibatch Loss: 0.550686, Training Accuracy: 0.835938\n",
      "Iter 9800, Minibatch Loss: 0.522968, Training Accuracy: 0.835938\n",
      "Iter 9900, Minibatch Loss: 0.412363, Training Accuracy: 0.906250\n",
      "Iter 10000, Minibatch Loss: 0.531744, Training Accuracy: 0.851562\n",
      "========> Validation Accuarcy: 0.838400, Testing Accuarcy: 0.839900\n",
      "Iter 10100, Minibatch Loss: 0.343336, Training Accuracy: 0.898438\n",
      "Iter 10200, Minibatch Loss: 0.336766, Training Accuracy: 0.890625\n",
      "Iter 10300, Minibatch Loss: 0.679075, Training Accuracy: 0.812500\n",
      "Iter 10400, Minibatch Loss: 0.333209, Training Accuracy: 0.898438\n",
      "Iter 10500, Minibatch Loss: 0.552378, Training Accuracy: 0.812500\n",
      "Iter 10600, Minibatch Loss: 0.501618, Training Accuracy: 0.828125\n",
      "Iter 10700, Minibatch Loss: 0.521989, Training Accuracy: 0.828125\n",
      "Iter 10800, Minibatch Loss: 0.531735, Training Accuracy: 0.796875\n",
      "Iter 10900, Minibatch Loss: 0.414596, Training Accuracy: 0.890625\n",
      "Iter 11000, Minibatch Loss: 0.380350, Training Accuracy: 0.851562\n",
      "Iter 11100, Minibatch Loss: 0.559060, Training Accuracy: 0.804688\n",
      "Iter 11200, Minibatch Loss: 0.388982, Training Accuracy: 0.882812\n",
      "Iter 11300, Minibatch Loss: 0.362564, Training Accuracy: 0.890625\n",
      "Iter 11400, Minibatch Loss: 0.438646, Training Accuracy: 0.851562\n",
      "Iter 11500, Minibatch Loss: 0.437011, Training Accuracy: 0.835938\n",
      "Iter 11600, Minibatch Loss: 0.489975, Training Accuracy: 0.851562\n",
      "Iter 11700, Minibatch Loss: 0.381743, Training Accuracy: 0.906250\n",
      "Iter 11800, Minibatch Loss: 0.611110, Training Accuracy: 0.804688\n",
      "Iter 11900, Minibatch Loss: 0.506701, Training Accuracy: 0.843750\n",
      "Iter 12000, Minibatch Loss: 0.511509, Training Accuracy: 0.882812\n",
      "Iter 12100, Minibatch Loss: 0.455265, Training Accuracy: 0.843750\n",
      "Iter 12200, Minibatch Loss: 0.502958, Training Accuracy: 0.828125\n",
      "Iter 12300, Minibatch Loss: 0.562905, Training Accuracy: 0.835938\n",
      "Iter 12400, Minibatch Loss: 0.417993, Training Accuracy: 0.859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 12500, Minibatch Loss: 0.643274, Training Accuracy: 0.796875\n",
      "Iter 12600, Minibatch Loss: 0.381485, Training Accuracy: 0.859375\n",
      "Iter 12700, Minibatch Loss: 0.406293, Training Accuracy: 0.898438\n",
      "Iter 12800, Minibatch Loss: 0.325394, Training Accuracy: 0.882812\n",
      "Iter 12900, Minibatch Loss: 0.435933, Training Accuracy: 0.843750\n",
      "Iter 13000, Minibatch Loss: 0.375936, Training Accuracy: 0.851562\n",
      "Iter 13100, Minibatch Loss: 0.406684, Training Accuracy: 0.898438\n",
      "Iter 13200, Minibatch Loss: 0.456368, Training Accuracy: 0.828125\n",
      "Iter 13300, Minibatch Loss: 0.525112, Training Accuracy: 0.843750\n",
      "Iter 13400, Minibatch Loss: 0.389000, Training Accuracy: 0.890625\n",
      "Iter 13500, Minibatch Loss: 0.519540, Training Accuracy: 0.835938\n",
      "Iter 13600, Minibatch Loss: 0.366700, Training Accuracy: 0.890625\n",
      "Iter 13700, Minibatch Loss: 0.430693, Training Accuracy: 0.867188\n",
      "Iter 13800, Minibatch Loss: 0.264417, Training Accuracy: 0.921875\n",
      "Iter 13900, Minibatch Loss: 0.439573, Training Accuracy: 0.867188\n",
      "Iter 14000, Minibatch Loss: 0.370004, Training Accuracy: 0.898438\n",
      "Iter 14100, Minibatch Loss: 0.391478, Training Accuracy: 0.867188\n",
      "Iter 14200, Minibatch Loss: 0.332296, Training Accuracy: 0.890625\n",
      "Iter 14300, Minibatch Loss: 0.439521, Training Accuracy: 0.867188\n",
      "Iter 14400, Minibatch Loss: 0.491203, Training Accuracy: 0.851562\n",
      "Iter 14500, Minibatch Loss: 0.547177, Training Accuracy: 0.859375\n",
      "Iter 14600, Minibatch Loss: 0.382288, Training Accuracy: 0.875000\n",
      "Iter 14700, Minibatch Loss: 0.501956, Training Accuracy: 0.843750\n",
      "Iter 14800, Minibatch Loss: 0.393795, Training Accuracy: 0.875000\n",
      "Iter 14900, Minibatch Loss: 0.416129, Training Accuracy: 0.867188\n",
      "Iter 15000, Minibatch Loss: 0.290263, Training Accuracy: 0.906250\n",
      "========> Validation Accuarcy: 0.867200, Testing Accuarcy: 0.870000\n",
      "Iter 15100, Minibatch Loss: 0.560180, Training Accuracy: 0.835938\n",
      "Iter 15200, Minibatch Loss: 0.493381, Training Accuracy: 0.820312\n",
      "Iter 15300, Minibatch Loss: 0.488263, Training Accuracy: 0.875000\n",
      "Iter 15400, Minibatch Loss: 0.299816, Training Accuracy: 0.890625\n",
      "Iter 15500, Minibatch Loss: 0.385476, Training Accuracy: 0.867188\n",
      "Iter 15600, Minibatch Loss: 0.456266, Training Accuracy: 0.835938\n",
      "Iter 15700, Minibatch Loss: 0.318649, Training Accuracy: 0.882812\n",
      "Iter 15800, Minibatch Loss: 0.482557, Training Accuracy: 0.820312\n",
      "Iter 15900, Minibatch Loss: 0.315254, Training Accuracy: 0.906250\n",
      "Iter 16000, Minibatch Loss: 0.572123, Training Accuracy: 0.859375\n",
      "Iter 16100, Minibatch Loss: 0.493933, Training Accuracy: 0.843750\n",
      "Iter 16200, Minibatch Loss: 0.388350, Training Accuracy: 0.890625\n",
      "Iter 16300, Minibatch Loss: 0.289441, Training Accuracy: 0.906250\n",
      "Iter 16400, Minibatch Loss: 0.454312, Training Accuracy: 0.851562\n",
      "Iter 16500, Minibatch Loss: 0.443927, Training Accuracy: 0.875000\n",
      "Iter 16600, Minibatch Loss: 0.407676, Training Accuracy: 0.882812\n",
      "Iter 16700, Minibatch Loss: 0.395363, Training Accuracy: 0.859375\n",
      "Iter 16800, Minibatch Loss: 0.238007, Training Accuracy: 0.921875\n",
      "Iter 16900, Minibatch Loss: 0.270442, Training Accuracy: 0.914062\n",
      "Iter 17000, Minibatch Loss: 0.358086, Training Accuracy: 0.882812\n",
      "Iter 17100, Minibatch Loss: 0.234300, Training Accuracy: 0.937500\n",
      "Iter 17200, Minibatch Loss: 0.257818, Training Accuracy: 0.914062\n",
      "Iter 17300, Minibatch Loss: 0.409087, Training Accuracy: 0.875000\n",
      "Iter 17400, Minibatch Loss: 0.358154, Training Accuracy: 0.890625\n",
      "Iter 17500, Minibatch Loss: 0.452738, Training Accuracy: 0.835938\n",
      "Iter 17600, Minibatch Loss: 0.281376, Training Accuracy: 0.906250\n",
      "Iter 17700, Minibatch Loss: 0.330349, Training Accuracy: 0.882812\n",
      "Iter 17800, Minibatch Loss: 0.436366, Training Accuracy: 0.867188\n",
      "Iter 17900, Minibatch Loss: 0.363726, Training Accuracy: 0.867188\n",
      "Iter 18000, Minibatch Loss: 0.320899, Training Accuracy: 0.898438\n",
      "Iter 18100, Minibatch Loss: 0.366865, Training Accuracy: 0.890625\n",
      "Iter 18200, Minibatch Loss: 0.249586, Training Accuracy: 0.921875\n",
      "Iter 18300, Minibatch Loss: 0.315331, Training Accuracy: 0.898438\n",
      "Iter 18400, Minibatch Loss: 0.361592, Training Accuracy: 0.906250\n",
      "Iter 18500, Minibatch Loss: 0.200015, Training Accuracy: 0.953125\n",
      "Iter 18600, Minibatch Loss: 0.223244, Training Accuracy: 0.921875\n",
      "Iter 18700, Minibatch Loss: 0.374753, Training Accuracy: 0.898438\n",
      "Iter 18800, Minibatch Loss: 0.176025, Training Accuracy: 0.937500\n",
      "Iter 18900, Minibatch Loss: 0.243216, Training Accuracy: 0.937500\n",
      "Iter 19000, Minibatch Loss: 0.453023, Training Accuracy: 0.843750\n",
      "Iter 19100, Minibatch Loss: 0.283739, Training Accuracy: 0.921875\n",
      "Iter 19200, Minibatch Loss: 0.259657, Training Accuracy: 0.929688\n",
      "Iter 19300, Minibatch Loss: 0.283613, Training Accuracy: 0.914062\n",
      "Iter 19400, Minibatch Loss: 0.272837, Training Accuracy: 0.906250\n",
      "Iter 19500, Minibatch Loss: 0.334239, Training Accuracy: 0.906250\n",
      "Iter 19600, Minibatch Loss: 0.257532, Training Accuracy: 0.906250\n",
      "Iter 19700, Minibatch Loss: 0.281063, Training Accuracy: 0.914062\n",
      "Iter 19800, Minibatch Loss: 0.382783, Training Accuracy: 0.851562\n",
      "Iter 19900, Minibatch Loss: 0.241944, Training Accuracy: 0.929688\n",
      "Iter 20000, Minibatch Loss: 0.245993, Training Accuracy: 0.914062\n",
      "========> Validation Accuarcy: 0.898800, Testing Accuarcy: 0.895000\n",
      "Iter 20100, Minibatch Loss: 0.361944, Training Accuracy: 0.898438\n",
      "Iter 20200, Minibatch Loss: 0.228049, Training Accuracy: 0.937500\n",
      "Iter 20300, Minibatch Loss: 0.171124, Training Accuracy: 0.937500\n",
      "Iter 20400, Minibatch Loss: 0.258510, Training Accuracy: 0.906250\n",
      "Iter 20500, Minibatch Loss: 0.334995, Training Accuracy: 0.906250\n",
      "Iter 20600, Minibatch Loss: 0.246684, Training Accuracy: 0.921875\n",
      "Iter 20700, Minibatch Loss: 0.355934, Training Accuracy: 0.898438\n",
      "Iter 20800, Minibatch Loss: 0.327941, Training Accuracy: 0.859375\n",
      "Iter 20900, Minibatch Loss: 0.274084, Training Accuracy: 0.890625\n",
      "Iter 21000, Minibatch Loss: 0.294935, Training Accuracy: 0.906250\n",
      "Iter 21100, Minibatch Loss: 0.304054, Training Accuracy: 0.898438\n",
      "Iter 21200, Minibatch Loss: 0.356786, Training Accuracy: 0.914062\n",
      "Iter 21300, Minibatch Loss: 0.272075, Training Accuracy: 0.914062\n",
      "Iter 21400, Minibatch Loss: 0.419652, Training Accuracy: 0.882812\n",
      "Iter 21500, Minibatch Loss: 0.281745, Training Accuracy: 0.914062\n",
      "Iter 21600, Minibatch Loss: 0.349398, Training Accuracy: 0.890625\n",
      "Iter 21700, Minibatch Loss: 0.249555, Training Accuracy: 0.914062\n",
      "Iter 21800, Minibatch Loss: 0.353167, Training Accuracy: 0.898438\n",
      "Iter 21900, Minibatch Loss: 0.257057, Training Accuracy: 0.906250\n",
      "Iter 22000, Minibatch Loss: 0.371671, Training Accuracy: 0.890625\n",
      "Iter 22100, Minibatch Loss: 0.339479, Training Accuracy: 0.859375\n",
      "Iter 22200, Minibatch Loss: 0.241623, Training Accuracy: 0.921875\n",
      "Iter 22300, Minibatch Loss: 0.173340, Training Accuracy: 0.945312\n",
      "Iter 22400, Minibatch Loss: 0.412853, Training Accuracy: 0.867188\n",
      "Iter 22500, Minibatch Loss: 0.405043, Training Accuracy: 0.898438\n",
      "Iter 22600, Minibatch Loss: 0.412929, Training Accuracy: 0.859375\n",
      "Iter 22700, Minibatch Loss: 0.260352, Training Accuracy: 0.914062\n",
      "Iter 22800, Minibatch Loss: 0.305357, Training Accuracy: 0.898438\n",
      "Iter 22900, Minibatch Loss: 0.239083, Training Accuracy: 0.937500\n",
      "Iter 23000, Minibatch Loss: 0.256044, Training Accuracy: 0.929688\n",
      "Iter 23100, Minibatch Loss: 0.354624, Training Accuracy: 0.890625\n",
      "Iter 23200, Minibatch Loss: 0.334511, Training Accuracy: 0.906250\n",
      "Iter 23300, Minibatch Loss: 0.384777, Training Accuracy: 0.906250\n",
      "Iter 23400, Minibatch Loss: 0.206711, Training Accuracy: 0.937500\n",
      "Iter 23500, Minibatch Loss: 0.333511, Training Accuracy: 0.898438\n",
      "Iter 23600, Minibatch Loss: 0.203839, Training Accuracy: 0.937500\n",
      "Iter 23700, Minibatch Loss: 0.313342, Training Accuracy: 0.890625\n",
      "Iter 23800, Minibatch Loss: 0.414428, Training Accuracy: 0.843750\n",
      "Iter 23900, Minibatch Loss: 0.369083, Training Accuracy: 0.890625\n",
      "Iter 24000, Minibatch Loss: 0.441768, Training Accuracy: 0.851562\n",
      "Iter 24100, Minibatch Loss: 0.284506, Training Accuracy: 0.906250\n",
      "Iter 24200, Minibatch Loss: 0.325369, Training Accuracy: 0.906250\n",
      "Iter 24300, Minibatch Loss: 0.275817, Training Accuracy: 0.945312\n",
      "Iter 24400, Minibatch Loss: 0.185724, Training Accuracy: 0.960938\n",
      "Iter 24500, Minibatch Loss: 0.301124, Training Accuracy: 0.890625\n",
      "Iter 24600, Minibatch Loss: 0.471088, Training Accuracy: 0.867188\n",
      "Iter 24700, Minibatch Loss: 0.352472, Training Accuracy: 0.851562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 24800, Minibatch Loss: 0.206541, Training Accuracy: 0.929688\n",
      "Iter 24900, Minibatch Loss: 0.178119, Training Accuracy: 0.945312\n",
      "Iter 25000, Minibatch Loss: 0.340244, Training Accuracy: 0.875000\n",
      "========> Validation Accuarcy: 0.905400, Testing Accuarcy: 0.904700\n",
      "Iter 25100, Minibatch Loss: 0.292307, Training Accuracy: 0.906250\n",
      "Iter 25200, Minibatch Loss: 0.201705, Training Accuracy: 0.921875\n",
      "Iter 25300, Minibatch Loss: 0.361588, Training Accuracy: 0.867188\n",
      "Iter 25400, Minibatch Loss: 0.315385, Training Accuracy: 0.914062\n",
      "Iter 25500, Minibatch Loss: 0.200823, Training Accuracy: 0.921875\n",
      "Iter 25600, Minibatch Loss: 0.214021, Training Accuracy: 0.929688\n",
      "Iter 25700, Minibatch Loss: 0.321480, Training Accuracy: 0.898438\n",
      "Iter 25800, Minibatch Loss: 0.275712, Training Accuracy: 0.906250\n",
      "Iter 25900, Minibatch Loss: 0.328479, Training Accuracy: 0.914062\n",
      "Iter 26000, Minibatch Loss: 0.228756, Training Accuracy: 0.914062\n",
      "Iter 26100, Minibatch Loss: 0.116678, Training Accuracy: 0.960938\n",
      "Iter 26200, Minibatch Loss: 0.200281, Training Accuracy: 0.953125\n",
      "Iter 26300, Minibatch Loss: 0.369103, Training Accuracy: 0.890625\n",
      "Iter 26400, Minibatch Loss: 0.334249, Training Accuracy: 0.875000\n",
      "Iter 26500, Minibatch Loss: 0.167589, Training Accuracy: 0.937500\n",
      "Iter 26600, Minibatch Loss: 0.224098, Training Accuracy: 0.921875\n",
      "Iter 26700, Minibatch Loss: 0.290248, Training Accuracy: 0.898438\n",
      "Iter 26800, Minibatch Loss: 0.268646, Training Accuracy: 0.906250\n",
      "Iter 26900, Minibatch Loss: 0.260220, Training Accuracy: 0.906250\n",
      "Iter 27000, Minibatch Loss: 0.292126, Training Accuracy: 0.914062\n",
      "Iter 27100, Minibatch Loss: 0.185847, Training Accuracy: 0.937500\n",
      "Iter 27200, Minibatch Loss: 0.283627, Training Accuracy: 0.882812\n",
      "Iter 27300, Minibatch Loss: 0.283699, Training Accuracy: 0.882812\n",
      "Iter 27400, Minibatch Loss: 0.284639, Training Accuracy: 0.929688\n",
      "Iter 27500, Minibatch Loss: 0.156764, Training Accuracy: 0.945312\n",
      "Iter 27600, Minibatch Loss: 0.199189, Training Accuracy: 0.921875\n",
      "Iter 27700, Minibatch Loss: 0.342470, Training Accuracy: 0.890625\n",
      "Iter 27800, Minibatch Loss: 0.239860, Training Accuracy: 0.937500\n",
      "Iter 27900, Minibatch Loss: 0.180108, Training Accuracy: 0.937500\n",
      "Iter 28000, Minibatch Loss: 0.207515, Training Accuracy: 0.914062\n",
      "Iter 28100, Minibatch Loss: 0.158706, Training Accuracy: 0.945312\n",
      "Iter 28200, Minibatch Loss: 0.324402, Training Accuracy: 0.906250\n",
      "Iter 28300, Minibatch Loss: 0.213721, Training Accuracy: 0.906250\n",
      "Iter 28400, Minibatch Loss: 0.198454, Training Accuracy: 0.960938\n",
      "Iter 28500, Minibatch Loss: 0.349150, Training Accuracy: 0.914062\n",
      "Iter 28600, Minibatch Loss: 0.242154, Training Accuracy: 0.945312\n",
      "Iter 28700, Minibatch Loss: 0.305364, Training Accuracy: 0.906250\n",
      "Iter 28800, Minibatch Loss: 0.164214, Training Accuracy: 0.937500\n",
      "Iter 28900, Minibatch Loss: 0.189163, Training Accuracy: 0.945312\n",
      "Iter 29000, Minibatch Loss: 0.266522, Training Accuracy: 0.929688\n",
      "Iter 29100, Minibatch Loss: 0.312784, Training Accuracy: 0.890625\n",
      "Iter 29200, Minibatch Loss: 0.380954, Training Accuracy: 0.859375\n",
      "Iter 29300, Minibatch Loss: 0.240917, Training Accuracy: 0.937500\n",
      "Iter 29400, Minibatch Loss: 0.314558, Training Accuracy: 0.898438\n",
      "Iter 29500, Minibatch Loss: 0.318038, Training Accuracy: 0.906250\n",
      "Iter 29600, Minibatch Loss: 0.239028, Training Accuracy: 0.929688\n",
      "Iter 29700, Minibatch Loss: 0.229957, Training Accuracy: 0.953125\n",
      "Iter 29800, Minibatch Loss: 0.226690, Training Accuracy: 0.929688\n",
      "Iter 29900, Minibatch Loss: 0.223018, Training Accuracy: 0.921875\n",
      "Iter 30000, Minibatch Loss: 0.298867, Training Accuracy: 0.898438\n",
      "========> Validation Accuarcy: 0.917800, Testing Accuarcy: 0.917600\n",
      "Iter 30100, Minibatch Loss: 0.319067, Training Accuracy: 0.921875\n",
      "Iter 30200, Minibatch Loss: 0.209395, Training Accuracy: 0.945312\n",
      "Iter 30300, Minibatch Loss: 0.390315, Training Accuracy: 0.914062\n",
      "Iter 30400, Minibatch Loss: 0.197920, Training Accuracy: 0.929688\n",
      "Iter 30500, Minibatch Loss: 0.170387, Training Accuracy: 0.968750\n",
      "Iter 30600, Minibatch Loss: 0.172965, Training Accuracy: 0.960938\n",
      "Iter 30700, Minibatch Loss: 0.238483, Training Accuracy: 0.914062\n",
      "Iter 30800, Minibatch Loss: 0.159856, Training Accuracy: 0.953125\n",
      "Iter 30900, Minibatch Loss: 0.108122, Training Accuracy: 0.960938\n",
      "Iter 31000, Minibatch Loss: 0.169349, Training Accuracy: 0.945312\n",
      "Iter 31100, Minibatch Loss: 0.187616, Training Accuracy: 0.960938\n",
      "Iter 31200, Minibatch Loss: 0.226721, Training Accuracy: 0.906250\n",
      "Iter 31300, Minibatch Loss: 0.245507, Training Accuracy: 0.929688\n",
      "Iter 31400, Minibatch Loss: 0.223062, Training Accuracy: 0.898438\n",
      "Iter 31500, Minibatch Loss: 0.178383, Training Accuracy: 0.914062\n",
      "Iter 31600, Minibatch Loss: 0.179010, Training Accuracy: 0.937500\n",
      "Iter 31700, Minibatch Loss: 0.224608, Training Accuracy: 0.929688\n",
      "Iter 31800, Minibatch Loss: 0.305826, Training Accuracy: 0.898438\n",
      "Iter 31900, Minibatch Loss: 0.238493, Training Accuracy: 0.898438\n",
      "Iter 32000, Minibatch Loss: 0.118706, Training Accuracy: 0.960938\n",
      "Iter 32100, Minibatch Loss: 0.255714, Training Accuracy: 0.929688\n",
      "Iter 32200, Minibatch Loss: 0.295664, Training Accuracy: 0.898438\n",
      "Iter 32300, Minibatch Loss: 0.238792, Training Accuracy: 0.937500\n",
      "Iter 32400, Minibatch Loss: 0.334246, Training Accuracy: 0.914062\n",
      "Iter 32500, Minibatch Loss: 0.204274, Training Accuracy: 0.929688\n",
      "Iter 32600, Minibatch Loss: 0.180992, Training Accuracy: 0.937500\n",
      "Iter 32700, Minibatch Loss: 0.249298, Training Accuracy: 0.890625\n",
      "Iter 32800, Minibatch Loss: 0.276065, Training Accuracy: 0.937500\n",
      "Iter 32900, Minibatch Loss: 0.082850, Training Accuracy: 0.984375\n",
      "Iter 33000, Minibatch Loss: 0.375718, Training Accuracy: 0.890625\n",
      "Iter 33100, Minibatch Loss: 0.218280, Training Accuracy: 0.937500\n",
      "Iter 33200, Minibatch Loss: 0.237317, Training Accuracy: 0.937500\n",
      "Iter 33300, Minibatch Loss: 0.209219, Training Accuracy: 0.945312\n",
      "Iter 33400, Minibatch Loss: 0.293009, Training Accuracy: 0.890625\n",
      "Iter 33500, Minibatch Loss: 0.151786, Training Accuracy: 0.945312\n",
      "Iter 33600, Minibatch Loss: 0.203001, Training Accuracy: 0.953125\n",
      "Iter 33700, Minibatch Loss: 0.250070, Training Accuracy: 0.929688\n",
      "Iter 33800, Minibatch Loss: 0.241246, Training Accuracy: 0.945312\n",
      "Iter 33900, Minibatch Loss: 0.201114, Training Accuracy: 0.929688\n",
      "Iter 34000, Minibatch Loss: 0.185501, Training Accuracy: 0.945312\n",
      "Iter 34100, Minibatch Loss: 0.210801, Training Accuracy: 0.953125\n",
      "Iter 34200, Minibatch Loss: 0.275110, Training Accuracy: 0.914062\n",
      "Iter 34300, Minibatch Loss: 0.251920, Training Accuracy: 0.929688\n",
      "Iter 34400, Minibatch Loss: 0.230052, Training Accuracy: 0.929688\n",
      "Iter 34500, Minibatch Loss: 0.305504, Training Accuracy: 0.921875\n",
      "Iter 34600, Minibatch Loss: 0.104636, Training Accuracy: 0.976562\n",
      "Iter 34700, Minibatch Loss: 0.258505, Training Accuracy: 0.929688\n",
      "Iter 34800, Minibatch Loss: 0.298091, Training Accuracy: 0.914062\n",
      "Iter 34900, Minibatch Loss: 0.232156, Training Accuracy: 0.929688\n",
      "Iter 35000, Minibatch Loss: 0.336076, Training Accuracy: 0.906250\n",
      "========> Validation Accuarcy: 0.920800, Testing Accuarcy: 0.920700\n",
      "Iter 35100, Minibatch Loss: 0.204830, Training Accuracy: 0.945312\n",
      "Iter 35200, Minibatch Loss: 0.385418, Training Accuracy: 0.921875\n",
      "Iter 35300, Minibatch Loss: 0.237936, Training Accuracy: 0.929688\n",
      "Iter 35400, Minibatch Loss: 0.195972, Training Accuracy: 0.945312\n",
      "Iter 35500, Minibatch Loss: 0.220062, Training Accuracy: 0.914062\n",
      "Iter 35600, Minibatch Loss: 0.195317, Training Accuracy: 0.921875\n",
      "Iter 35700, Minibatch Loss: 0.182959, Training Accuracy: 0.953125\n",
      "Iter 35800, Minibatch Loss: 0.175910, Training Accuracy: 0.945312\n",
      "Iter 35900, Minibatch Loss: 0.181232, Training Accuracy: 0.921875\n",
      "Iter 36000, Minibatch Loss: 0.258426, Training Accuracy: 0.921875\n",
      "Iter 36100, Minibatch Loss: 0.210557, Training Accuracy: 0.953125\n",
      "Iter 36200, Minibatch Loss: 0.150595, Training Accuracy: 0.968750\n",
      "Iter 36300, Minibatch Loss: 0.211241, Training Accuracy: 0.937500\n",
      "Iter 36400, Minibatch Loss: 0.219265, Training Accuracy: 0.929688\n",
      "Iter 36500, Minibatch Loss: 0.236438, Training Accuracy: 0.914062\n",
      "Iter 36600, Minibatch Loss: 0.172958, Training Accuracy: 0.945312\n",
      "Iter 36700, Minibatch Loss: 0.199203, Training Accuracy: 0.953125\n",
      "Iter 36800, Minibatch Loss: 0.157809, Training Accuracy: 0.953125\n",
      "Iter 36900, Minibatch Loss: 0.416038, Training Accuracy: 0.890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 37000, Minibatch Loss: 0.360373, Training Accuracy: 0.867188\n",
      "Iter 37100, Minibatch Loss: 0.396344, Training Accuracy: 0.890625\n",
      "Iter 37200, Minibatch Loss: 0.278989, Training Accuracy: 0.906250\n",
      "Iter 37300, Minibatch Loss: 0.201067, Training Accuracy: 0.937500\n",
      "Iter 37400, Minibatch Loss: 0.281370, Training Accuracy: 0.906250\n",
      "Iter 37500, Minibatch Loss: 0.242923, Training Accuracy: 0.929688\n",
      "Iter 37600, Minibatch Loss: 0.239631, Training Accuracy: 0.937500\n",
      "Iter 37700, Minibatch Loss: 0.205103, Training Accuracy: 0.937500\n",
      "Iter 37800, Minibatch Loss: 0.248270, Training Accuracy: 0.929688\n",
      "Iter 37900, Minibatch Loss: 0.115223, Training Accuracy: 0.960938\n",
      "Iter 38000, Minibatch Loss: 0.207170, Training Accuracy: 0.937500\n",
      "Iter 38100, Minibatch Loss: 0.159263, Training Accuracy: 0.960938\n",
      "Iter 38200, Minibatch Loss: 0.168450, Training Accuracy: 0.914062\n",
      "Iter 38300, Minibatch Loss: 0.181149, Training Accuracy: 0.953125\n",
      "Iter 38400, Minibatch Loss: 0.198623, Training Accuracy: 0.929688\n",
      "Iter 38500, Minibatch Loss: 0.223363, Training Accuracy: 0.914062\n",
      "Iter 38600, Minibatch Loss: 0.305630, Training Accuracy: 0.921875\n",
      "Iter 38700, Minibatch Loss: 0.139986, Training Accuracy: 0.945312\n",
      "Iter 38800, Minibatch Loss: 0.183229, Training Accuracy: 0.945312\n",
      "Iter 38900, Minibatch Loss: 0.223892, Training Accuracy: 0.960938\n",
      "Iter 39000, Minibatch Loss: 0.279564, Training Accuracy: 0.914062\n",
      "Iter 39100, Minibatch Loss: 0.203221, Training Accuracy: 0.921875\n",
      "Iter 39200, Minibatch Loss: 0.235828, Training Accuracy: 0.914062\n",
      "Iter 39300, Minibatch Loss: 0.370403, Training Accuracy: 0.882812\n",
      "Iter 39400, Minibatch Loss: 0.234099, Training Accuracy: 0.929688\n",
      "Iter 39500, Minibatch Loss: 0.225714, Training Accuracy: 0.937500\n",
      "Iter 39600, Minibatch Loss: 0.287327, Training Accuracy: 0.921875\n",
      "Iter 39700, Minibatch Loss: 0.252857, Training Accuracy: 0.898438\n",
      "Iter 39800, Minibatch Loss: 0.208448, Training Accuracy: 0.953125\n",
      "Iter 39900, Minibatch Loss: 0.226970, Training Accuracy: 0.914062\n",
      "Iter 40000, Minibatch Loss: 0.185217, Training Accuracy: 0.937500\n",
      "========> Validation Accuarcy: 0.928000, Testing Accuarcy: 0.928800\n",
      "Iter 40100, Minibatch Loss: 0.101374, Training Accuracy: 0.968750\n",
      "Iter 40200, Minibatch Loss: 0.198899, Training Accuracy: 0.929688\n",
      "Iter 40300, Minibatch Loss: 0.203728, Training Accuracy: 0.921875\n",
      "Iter 40400, Minibatch Loss: 0.106360, Training Accuracy: 0.984375\n",
      "Iter 40500, Minibatch Loss: 0.156621, Training Accuracy: 0.937500\n",
      "Iter 40600, Minibatch Loss: 0.198731, Training Accuracy: 0.953125\n",
      "Iter 40700, Minibatch Loss: 0.253405, Training Accuracy: 0.906250\n",
      "Iter 40800, Minibatch Loss: 0.206188, Training Accuracy: 0.921875\n",
      "Iter 40900, Minibatch Loss: 0.130051, Training Accuracy: 0.976562\n",
      "Iter 41000, Minibatch Loss: 0.202722, Training Accuracy: 0.953125\n",
      "Iter 41100, Minibatch Loss: 0.127660, Training Accuracy: 0.976562\n",
      "Iter 41200, Minibatch Loss: 0.067600, Training Accuracy: 0.984375\n",
      "Iter 41300, Minibatch Loss: 0.170131, Training Accuracy: 0.953125\n",
      "Iter 41400, Minibatch Loss: 0.155842, Training Accuracy: 0.945312\n",
      "Iter 41500, Minibatch Loss: 0.106537, Training Accuracy: 0.976562\n",
      "Iter 41600, Minibatch Loss: 0.283429, Training Accuracy: 0.937500\n",
      "Iter 41700, Minibatch Loss: 0.217058, Training Accuracy: 0.937500\n",
      "Iter 41800, Minibatch Loss: 0.118354, Training Accuracy: 0.960938\n",
      "Iter 41900, Minibatch Loss: 0.180598, Training Accuracy: 0.914062\n",
      "Iter 42000, Minibatch Loss: 0.185748, Training Accuracy: 0.953125\n",
      "Iter 42100, Minibatch Loss: 0.156224, Training Accuracy: 0.953125\n",
      "Iter 42200, Minibatch Loss: 0.143743, Training Accuracy: 0.960938\n",
      "Iter 42300, Minibatch Loss: 0.096736, Training Accuracy: 0.968750\n",
      "Iter 42400, Minibatch Loss: 0.155606, Training Accuracy: 0.968750\n",
      "Iter 42500, Minibatch Loss: 0.207131, Training Accuracy: 0.937500\n",
      "Iter 42600, Minibatch Loss: 0.107968, Training Accuracy: 0.968750\n",
      "Iter 42700, Minibatch Loss: 0.160490, Training Accuracy: 0.960938\n",
      "Iter 42800, Minibatch Loss: 0.242383, Training Accuracy: 0.914062\n",
      "Iter 42900, Minibatch Loss: 0.179466, Training Accuracy: 0.945312\n",
      "Iter 43000, Minibatch Loss: 0.229832, Training Accuracy: 0.921875\n",
      "Iter 43100, Minibatch Loss: 0.144342, Training Accuracy: 0.968750\n",
      "Iter 43200, Minibatch Loss: 0.158530, Training Accuracy: 0.929688\n",
      "Iter 43300, Minibatch Loss: 0.201165, Training Accuracy: 0.890625\n",
      "Iter 43400, Minibatch Loss: 0.150450, Training Accuracy: 0.945312\n",
      "Iter 43500, Minibatch Loss: 0.186240, Training Accuracy: 0.937500\n",
      "Iter 43600, Minibatch Loss: 0.057573, Training Accuracy: 0.984375\n",
      "Iter 43700, Minibatch Loss: 0.186958, Training Accuracy: 0.945312\n",
      "Iter 43800, Minibatch Loss: 0.224490, Training Accuracy: 0.945312\n",
      "Iter 43900, Minibatch Loss: 0.152665, Training Accuracy: 0.960938\n",
      "Iter 44000, Minibatch Loss: 0.200011, Training Accuracy: 0.929688\n",
      "Iter 44100, Minibatch Loss: 0.091298, Training Accuracy: 0.960938\n",
      "Iter 44200, Minibatch Loss: 0.223041, Training Accuracy: 0.960938\n",
      "Iter 44300, Minibatch Loss: 0.200848, Training Accuracy: 0.945312\n",
      "Iter 44400, Minibatch Loss: 0.123549, Training Accuracy: 0.953125\n",
      "Iter 44500, Minibatch Loss: 0.190730, Training Accuracy: 0.929688\n",
      "Iter 44600, Minibatch Loss: 0.128651, Training Accuracy: 0.976562\n",
      "Iter 44700, Minibatch Loss: 0.132903, Training Accuracy: 0.960938\n",
      "Iter 44800, Minibatch Loss: 0.130288, Training Accuracy: 0.945312\n",
      "Iter 44900, Minibatch Loss: 0.230664, Training Accuracy: 0.937500\n",
      "Iter 45000, Minibatch Loss: 0.114319, Training Accuracy: 0.960938\n",
      "========> Validation Accuarcy: 0.931000, Testing Accuarcy: 0.930900\n",
      "Iter 45100, Minibatch Loss: 0.102176, Training Accuracy: 0.960938\n",
      "Iter 45200, Minibatch Loss: 0.217776, Training Accuracy: 0.929688\n",
      "Iter 45300, Minibatch Loss: 0.163309, Training Accuracy: 0.945312\n",
      "Iter 45400, Minibatch Loss: 0.172869, Training Accuracy: 0.937500\n",
      "Iter 45500, Minibatch Loss: 0.197324, Training Accuracy: 0.960938\n",
      "Iter 45600, Minibatch Loss: 0.277205, Training Accuracy: 0.906250\n",
      "Iter 45700, Minibatch Loss: 0.247562, Training Accuracy: 0.937500\n",
      "Iter 45800, Minibatch Loss: 0.168946, Training Accuracy: 0.937500\n",
      "Iter 45900, Minibatch Loss: 0.279769, Training Accuracy: 0.906250\n",
      "Iter 46000, Minibatch Loss: 0.233501, Training Accuracy: 0.945312\n",
      "Iter 46100, Minibatch Loss: 0.139730, Training Accuracy: 0.953125\n",
      "Iter 46200, Minibatch Loss: 0.177008, Training Accuracy: 0.945312\n",
      "Iter 46300, Minibatch Loss: 0.206843, Training Accuracy: 0.906250\n",
      "Iter 46400, Minibatch Loss: 0.154060, Training Accuracy: 0.960938\n",
      "Iter 46500, Minibatch Loss: 0.206754, Training Accuracy: 0.914062\n",
      "Iter 46600, Minibatch Loss: 0.180785, Training Accuracy: 0.945312\n",
      "Iter 46700, Minibatch Loss: 0.178030, Training Accuracy: 0.929688\n",
      "Iter 46800, Minibatch Loss: 0.295534, Training Accuracy: 0.906250\n",
      "Iter 46900, Minibatch Loss: 0.214909, Training Accuracy: 0.953125\n",
      "Iter 47000, Minibatch Loss: 0.242106, Training Accuracy: 0.914062\n",
      "Iter 47100, Minibatch Loss: 0.239359, Training Accuracy: 0.937500\n",
      "Iter 47200, Minibatch Loss: 0.196677, Training Accuracy: 0.921875\n",
      "Iter 47300, Minibatch Loss: 0.210994, Training Accuracy: 0.945312\n",
      "Iter 47400, Minibatch Loss: 0.161584, Training Accuracy: 0.960938\n",
      "Iter 47500, Minibatch Loss: 0.175478, Training Accuracy: 0.929688\n",
      "Iter 47600, Minibatch Loss: 0.138570, Training Accuracy: 0.953125\n",
      "Iter 47700, Minibatch Loss: 0.201942, Training Accuracy: 0.921875\n",
      "Iter 47800, Minibatch Loss: 0.141265, Training Accuracy: 0.960938\n",
      "Iter 47900, Minibatch Loss: 0.115868, Training Accuracy: 0.945312\n",
      "Iter 48000, Minibatch Loss: 0.203164, Training Accuracy: 0.968750\n",
      "Iter 48100, Minibatch Loss: 0.109222, Training Accuracy: 0.953125\n",
      "Iter 48200, Minibatch Loss: 0.121653, Training Accuracy: 0.968750\n",
      "Iter 48300, Minibatch Loss: 0.109514, Training Accuracy: 0.968750\n",
      "Iter 48400, Minibatch Loss: 0.133966, Training Accuracy: 0.953125\n",
      "Iter 48500, Minibatch Loss: 0.119496, Training Accuracy: 0.976562\n",
      "Iter 48600, Minibatch Loss: 0.195164, Training Accuracy: 0.945312\n",
      "Iter 48700, Minibatch Loss: 0.163600, Training Accuracy: 0.960938\n",
      "Iter 48800, Minibatch Loss: 0.111244, Training Accuracy: 0.960938\n",
      "Iter 48900, Minibatch Loss: 0.169768, Training Accuracy: 0.937500\n",
      "Iter 49000, Minibatch Loss: 0.215293, Training Accuracy: 0.945312\n",
      "Iter 49100, Minibatch Loss: 0.228439, Training Accuracy: 0.906250\n",
      "Iter 49200, Minibatch Loss: 0.285262, Training Accuracy: 0.914062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 49300, Minibatch Loss: 0.293917, Training Accuracy: 0.914062\n",
      "Iter 49400, Minibatch Loss: 0.266118, Training Accuracy: 0.906250\n",
      "Iter 49500, Minibatch Loss: 0.137051, Training Accuracy: 0.960938\n",
      "Iter 49600, Minibatch Loss: 0.267811, Training Accuracy: 0.937500\n",
      "Iter 49700, Minibatch Loss: 0.145734, Training Accuracy: 0.945312\n",
      "Iter 49800, Minibatch Loss: 0.204152, Training Accuracy: 0.937500\n",
      "Iter 49900, Minibatch Loss: 0.176955, Training Accuracy: 0.953125\n",
      "Iter 50000, Minibatch Loss: 0.089453, Training Accuracy: 0.984375\n",
      "========> Validation Accuarcy: 0.933600, Testing Accuarcy: 0.932100\n",
      "Iter 50100, Minibatch Loss: 0.215292, Training Accuracy: 0.937500\n",
      "Iter 50200, Minibatch Loss: 0.253161, Training Accuracy: 0.914062\n",
      "Iter 50300, Minibatch Loss: 0.210871, Training Accuracy: 0.937500\n",
      "Iter 50400, Minibatch Loss: 0.156512, Training Accuracy: 0.929688\n",
      "Iter 50500, Minibatch Loss: 0.089051, Training Accuracy: 0.968750\n",
      "Iter 50600, Minibatch Loss: 0.096929, Training Accuracy: 0.984375\n",
      "Iter 50700, Minibatch Loss: 0.123864, Training Accuracy: 0.960938\n",
      "Iter 50800, Minibatch Loss: 0.169779, Training Accuracy: 0.929688\n",
      "Iter 50900, Minibatch Loss: 0.161164, Training Accuracy: 0.937500\n",
      "Iter 51000, Minibatch Loss: 0.233649, Training Accuracy: 0.921875\n",
      "Iter 51100, Minibatch Loss: 0.102952, Training Accuracy: 0.984375\n",
      "Iter 51200, Minibatch Loss: 0.223783, Training Accuracy: 0.960938\n",
      "Iter 51300, Minibatch Loss: 0.182464, Training Accuracy: 0.953125\n",
      "Iter 51400, Minibatch Loss: 0.160616, Training Accuracy: 0.929688\n",
      "Iter 51500, Minibatch Loss: 0.109974, Training Accuracy: 0.968750\n",
      "Iter 51600, Minibatch Loss: 0.191076, Training Accuracy: 0.937500\n",
      "Iter 51700, Minibatch Loss: 0.147663, Training Accuracy: 0.937500\n",
      "Iter 51800, Minibatch Loss: 0.096013, Training Accuracy: 0.976562\n",
      "Iter 51900, Minibatch Loss: 0.230439, Training Accuracy: 0.937500\n",
      "Iter 52000, Minibatch Loss: 0.188165, Training Accuracy: 0.937500\n",
      "Iter 52100, Minibatch Loss: 0.120239, Training Accuracy: 0.960938\n",
      "Iter 52200, Minibatch Loss: 0.126154, Training Accuracy: 0.960938\n",
      "Iter 52300, Minibatch Loss: 0.134768, Training Accuracy: 0.960938\n",
      "Iter 52400, Minibatch Loss: 0.129499, Training Accuracy: 0.953125\n",
      "Iter 52500, Minibatch Loss: 0.143713, Training Accuracy: 0.953125\n",
      "Iter 52600, Minibatch Loss: 0.119227, Training Accuracy: 0.968750\n",
      "Iter 52700, Minibatch Loss: 0.163635, Training Accuracy: 0.960938\n",
      "Iter 52800, Minibatch Loss: 0.080509, Training Accuracy: 0.976562\n",
      "Iter 52900, Minibatch Loss: 0.289682, Training Accuracy: 0.890625\n",
      "Iter 53000, Minibatch Loss: 0.228632, Training Accuracy: 0.929688\n",
      "Iter 53100, Minibatch Loss: 0.140098, Training Accuracy: 0.960938\n",
      "Iter 53200, Minibatch Loss: 0.091996, Training Accuracy: 0.960938\n",
      "Iter 53300, Minibatch Loss: 0.140960, Training Accuracy: 0.953125\n",
      "Iter 53400, Minibatch Loss: 0.080708, Training Accuracy: 0.984375\n",
      "Iter 53500, Minibatch Loss: 0.159871, Training Accuracy: 0.945312\n",
      "Iter 53600, Minibatch Loss: 0.119732, Training Accuracy: 0.968750\n",
      "Iter 53700, Minibatch Loss: 0.105140, Training Accuracy: 0.968750\n",
      "Iter 53800, Minibatch Loss: 0.162274, Training Accuracy: 0.953125\n",
      "Iter 53900, Minibatch Loss: 0.161363, Training Accuracy: 0.953125\n",
      "Iter 54000, Minibatch Loss: 0.177475, Training Accuracy: 0.929688\n",
      "Iter 54100, Minibatch Loss: 0.104262, Training Accuracy: 0.968750\n",
      "Iter 54200, Minibatch Loss: 0.277839, Training Accuracy: 0.921875\n",
      "Iter 54300, Minibatch Loss: 0.130938, Training Accuracy: 0.945312\n",
      "Iter 54400, Minibatch Loss: 0.151685, Training Accuracy: 0.937500\n",
      "Iter 54500, Minibatch Loss: 0.234349, Training Accuracy: 0.929688\n",
      "Iter 54600, Minibatch Loss: 0.292082, Training Accuracy: 0.914062\n",
      "Iter 54700, Minibatch Loss: 0.176382, Training Accuracy: 0.945312\n",
      "Iter 54800, Minibatch Loss: 0.112546, Training Accuracy: 0.960938\n",
      "Iter 54900, Minibatch Loss: 0.074173, Training Accuracy: 0.984375\n",
      "Iter 55000, Minibatch Loss: 0.282575, Training Accuracy: 0.921875\n",
      "========> Validation Accuarcy: 0.929800, Testing Accuarcy: 0.928200\n",
      "Iter 55100, Minibatch Loss: 0.165876, Training Accuracy: 0.960938\n",
      "Iter 55200, Minibatch Loss: 0.179013, Training Accuracy: 0.937500\n",
      "Iter 55300, Minibatch Loss: 0.160110, Training Accuracy: 0.945312\n",
      "Iter 55400, Minibatch Loss: 0.246431, Training Accuracy: 0.945312\n",
      "Iter 55500, Minibatch Loss: 0.171491, Training Accuracy: 0.953125\n",
      "Iter 55600, Minibatch Loss: 0.136057, Training Accuracy: 0.945312\n",
      "Iter 55700, Minibatch Loss: 0.185322, Training Accuracy: 0.960938\n",
      "Iter 55800, Minibatch Loss: 0.110474, Training Accuracy: 0.960938\n",
      "Iter 55900, Minibatch Loss: 0.137270, Training Accuracy: 0.976562\n",
      "Iter 56000, Minibatch Loss: 0.209504, Training Accuracy: 0.929688\n",
      "Iter 56100, Minibatch Loss: 0.181928, Training Accuracy: 0.953125\n",
      "Iter 56200, Minibatch Loss: 0.150319, Training Accuracy: 0.960938\n",
      "Iter 56300, Minibatch Loss: 0.121900, Training Accuracy: 0.968750\n",
      "Iter 56400, Minibatch Loss: 0.148165, Training Accuracy: 0.960938\n",
      "Iter 56500, Minibatch Loss: 0.235011, Training Accuracy: 0.921875\n",
      "Iter 56600, Minibatch Loss: 0.211838, Training Accuracy: 0.914062\n",
      "Iter 56700, Minibatch Loss: 0.199697, Training Accuracy: 0.929688\n",
      "Iter 56800, Minibatch Loss: 0.193833, Training Accuracy: 0.937500\n",
      "Iter 56900, Minibatch Loss: 0.080584, Training Accuracy: 0.968750\n",
      "Iter 57000, Minibatch Loss: 0.176203, Training Accuracy: 0.945312\n",
      "Iter 57100, Minibatch Loss: 0.214861, Training Accuracy: 0.929688\n",
      "Iter 57200, Minibatch Loss: 0.058482, Training Accuracy: 0.984375\n",
      "Iter 57300, Minibatch Loss: 0.199901, Training Accuracy: 0.937500\n",
      "Iter 57400, Minibatch Loss: 0.123953, Training Accuracy: 0.968750\n",
      "Iter 57500, Minibatch Loss: 0.114470, Training Accuracy: 0.953125\n",
      "Iter 57600, Minibatch Loss: 0.230533, Training Accuracy: 0.921875\n",
      "Iter 57700, Minibatch Loss: 0.101100, Training Accuracy: 0.976562\n",
      "Iter 57800, Minibatch Loss: 0.162985, Training Accuracy: 0.953125\n",
      "Iter 57900, Minibatch Loss: 0.142039, Training Accuracy: 0.976562\n",
      "Iter 58000, Minibatch Loss: 0.115851, Training Accuracy: 0.960938\n",
      "Iter 58100, Minibatch Loss: 0.287583, Training Accuracy: 0.929688\n",
      "Iter 58200, Minibatch Loss: 0.084339, Training Accuracy: 0.976562\n",
      "Iter 58300, Minibatch Loss: 0.158411, Training Accuracy: 0.945312\n",
      "Iter 58400, Minibatch Loss: 0.182809, Training Accuracy: 0.929688\n",
      "Iter 58500, Minibatch Loss: 0.069503, Training Accuracy: 0.984375\n",
      "Iter 58600, Minibatch Loss: 0.205568, Training Accuracy: 0.937500\n",
      "Iter 58700, Minibatch Loss: 0.133962, Training Accuracy: 0.953125\n",
      "Iter 58800, Minibatch Loss: 0.170555, Training Accuracy: 0.953125\n",
      "Iter 58900, Minibatch Loss: 0.340881, Training Accuracy: 0.898438\n",
      "Iter 59000, Minibatch Loss: 0.246549, Training Accuracy: 0.921875\n",
      "Iter 59100, Minibatch Loss: 0.186740, Training Accuracy: 0.929688\n",
      "Iter 59200, Minibatch Loss: 0.141242, Training Accuracy: 0.953125\n",
      "Iter 59300, Minibatch Loss: 0.147465, Training Accuracy: 0.937500\n",
      "Iter 59400, Minibatch Loss: 0.118542, Training Accuracy: 0.953125\n",
      "Iter 59500, Minibatch Loss: 0.125098, Training Accuracy: 0.953125\n",
      "Iter 59600, Minibatch Loss: 0.148800, Training Accuracy: 0.945312\n",
      "Iter 59700, Minibatch Loss: 0.248941, Training Accuracy: 0.914062\n",
      "Iter 59800, Minibatch Loss: 0.247047, Training Accuracy: 0.937500\n",
      "Iter 59900, Minibatch Loss: 0.138419, Training Accuracy: 0.968750\n",
      "Iter 60000, Minibatch Loss: 0.086199, Training Accuracy: 0.976562\n",
      "========> Validation Accuarcy: 0.937800, Testing Accuarcy: 0.936600\n"
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "train_results = []\n",
    "validation_results = []\n",
    "test_results = []\n",
    "\n",
    "while step * batch_size < training_iters:\n",
    "    batch_x, batch_y = mnist.train.next_batch(batch_size)    \n",
    "    batch_x = batch_x[:, idx_permute]\n",
    "    batch_x = batch_x.reshape([batch_size, n_steps, input_dims])\n",
    "\n",
    "    feed_dict = {\n",
    "        x : batch_x,\n",
    "        y : batch_y\n",
    "    }\n",
    "    cost_, accuracy_, step_,  _ = sess.run([cost, accuracy, global_step, optimizer], feed_dict=feed_dict)    \n",
    "    train_results.append((step_, cost_, accuracy_))    \n",
    "\n",
    "    if (step + 1) % display_step == 0:\n",
    "        print (\"Iter \" + str(step + 1) + \", Minibatch Loss: \" + \"{:.6f}\".format(cost_) \\\n",
    "        + \", Training Accuracy: \" + \"{:.6f}\".format(accuracy_))\n",
    "             \n",
    "    if (step + 1) % testing_step == 0:\n",
    "        \n",
    "        # validation performance\n",
    "        batch_x = mnist.validation.images\n",
    "        batch_y = mnist.validation.labels\n",
    "\n",
    "        # permute the data\n",
    "        batch_x = batch_x[:, idx_permute]        \n",
    "        batch_x = batch_x.reshape([-1, n_steps, input_dims])\n",
    "        feed_dict = {\n",
    "            x : batch_x,\n",
    "            y : batch_y\n",
    "        }\n",
    "        cost_, accuracy__, step_ = sess.run([cost, accuracy, global_step], feed_dict=feed_dict)\n",
    "        validation_results.append((step_, cost_, accuracy__))\n",
    "        \n",
    "        # test performance\n",
    "        batch_x = mnist.test.images\n",
    "        batch_y = mnist.test.labels\n",
    "        batch_x = batch_x[:, idx_permute]        \n",
    "        batch_x = batch_x.reshape([-1, n_steps, input_dims])\n",
    "        feed_dict = {\n",
    "            x : batch_x,\n",
    "            y : batch_y\n",
    "        }\n",
    "        cost_, accuracy_, step_ = sess.run([cost, accuracy, global_step], feed_dict=feed_dict)\n",
    "        test_results.append((step_, cost_, accuracy_))        \n",
    "        print (\"========> Validation Accuarcy: \" + \"{:.6f}\".format(accuracy__) \\\n",
    "        + \", Testing Accuarcy: \" + \"{:.6f}\".format(accuracy_)) \n",
    "    step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
